{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingRegressor, StackingCVRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = pd.read_csv('train_values.csv')\n",
    "trainY = pd.read_csv('train_labels.csv')\n",
    "testX = pd.read_csv('test_values.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainX.area__rucc = trainX.area__rucc.apply(lambda x: x.split(\" -\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX.area__rucc = trainX.area__rucc.astype(\"category\").cat.codes\n",
    "trainX.area__urban_influence = trainX.area__urban_influence.astype(\"category\").cat.codes\n",
    "trainX.econ__economic_typology = trainX.econ__economic_typology.astype(\"category\").cat.codes\n",
    "trainX.yr = trainX.yr.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainX = trainX.join(pd.get_dummies(data=trainX.area__rucc))\n",
    "# trainX = trainX.join(pd.get_dummies(data=trainX.area__urban_influence))\n",
    "# trainX = trainX.join(pd.get_dummies(data=trainX.econ__economic_typology))\n",
    "# trainX.yr = trainX.yr.astype(\"category\").cat.codes\n",
    "# trainX.drop(['area__rucc', 'area__urban_influence', 'econ__economic_typology'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in trainX.columns:\n",
    "    #trainX[col].fillna(trainX[col].mean(), inplace=True)\n",
    "    trainX[col].fillna(trainX[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in trainX.columns:\n",
    "#     #trainX[col].fillna(trainX[col].mean(), inplace=True)\n",
    "#     trainX[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>area__rucc</th>\n",
       "      <th>area__urban_influence</th>\n",
       "      <th>econ__economic_typology</th>\n",
       "      <th>econ__pct_civilian_labor</th>\n",
       "      <th>econ__pct_unemployment</th>\n",
       "      <th>econ__pct_uninsured_adults</th>\n",
       "      <th>econ__pct_uninsured_children</th>\n",
       "      <th>demo__pct_female</th>\n",
       "      <th>demo__pct_below_18_years_of_age</th>\n",
       "      <th>...</th>\n",
       "      <th>health__pct_diabetes</th>\n",
       "      <th>health__pct_low_birthweight</th>\n",
       "      <th>health__pct_excessive_drinking</th>\n",
       "      <th>health__pct_physical_inacticity</th>\n",
       "      <th>health__air_pollution_particulate_matter</th>\n",
       "      <th>health__homicides_per_100k</th>\n",
       "      <th>health__motor_vehicle_crash_deaths_per_100k</th>\n",
       "      <th>health__pop_per_dentist</th>\n",
       "      <th>health__pop_per_primary_care_physician</th>\n",
       "      <th>yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, area__rucc, area__urban_influence, econ__economic_typology, econ__pct_civilian_labor, econ__pct_unemployment, econ__pct_uninsured_adults, econ__pct_uninsured_children, demo__pct_female, demo__pct_below_18_years_of_age, demo__pct_aged_65_years_and_older, demo__pct_hispanic, demo__pct_non_hispanic_african_american, demo__pct_non_hispanic_white, demo__pct_american_indian_or_alaskan_native, demo__pct_asian, demo__pct_adults_less_than_a_high_school_diploma, demo__pct_adults_with_high_school_diploma, demo__pct_adults_with_some_college, demo__pct_adults_bachelors_or_higher, demo__birth_rate_per_1k, demo__death_rate_per_1k, health__pct_adult_obesity, health__pct_adult_smoking, health__pct_diabetes, health__pct_low_birthweight, health__pct_excessive_drinking, health__pct_physical_inacticity, health__air_pollution_particulate_matter, health__homicides_per_100k, health__motor_vehicle_crash_deaths_per_100k, health__pop_per_dentist, health__pop_per_primary_care_physician, yr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAN values finder\n",
    "trainX[pd.isnull(trainX).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX.drop('row_id', axis=1, inplace=True)\n",
    "trainY.drop('row_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "# trainX.drop(['yr',\n",
    "#  'health__air_pollution_particulate_matter',\n",
    "#  'health__homicides_per_100k',\n",
    "#  'demo__birth_rate_per_1k',\n",
    "#  'demo__death_rate_per_1k'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(trainX, trainY, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2398, 33)\n",
      "Training Labels Shape: (2398, 1)\n",
      "Testing Features Shape: (800, 33)\n",
      "Testing Labels Shape: (800, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# scaler = preprocessing.MaxAbsScaler()\n",
    "# scaler = preprocessing.Normalizer()\n",
    "\n",
    "# scaler.fit(train_features)\n",
    "# train_features = scaler.transform(train_features)\n",
    "# test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtr/ada params from submission 8 - RMSE : 3.4678\n",
    "adaDTR_adaParams8 = {'n_estimators':400, \n",
    "                     'random_state':736283, \n",
    "                     'learning_rate':1}\n",
    "\n",
    "adaDTR_dtrParams = {'max_depth':None, \n",
    "                    'min_samples_split':6, \n",
    "                    'max_features':'auto'}\n",
    "\n",
    "#etr params from submission 13 - RMSE : 3.2440\n",
    "etrParams = {'n_estimators':600, \n",
    "             'random_state':736283, \n",
    "             'max_depth':None, \n",
    "             'max_features':'auto', \n",
    "             'min_samples_split':2, \n",
    "             'n_jobs':-1}\n",
    "\n",
    "#xgb params from submission 22 - RMSE : 3.3746\n",
    "xgbParams = {'learning_rate':0.024, \n",
    "             'n_estimators':18000, \n",
    "             'max_depth':6, \n",
    "             'min_child_weight':1,\n",
    "             'gamma':0,\n",
    "             'subsample':0.7,\n",
    "             'colsample_bytree':0.6,\n",
    "             'reg_alpha':1,\n",
    "             'scale_pos_weight':1,\n",
    "             'random_state':736283, 'n_jobs':-1}\n",
    "\n",
    "rfgParams = {'n_estimators':390,\n",
    "             'max_features':'auto',\n",
    "             'min_samples_leaf':1,\n",
    "             'max_depth':None,\n",
    "             'random_state':736283,\n",
    "             'n_jobs':-1}\n",
    "\n",
    "etParams = {'criterion':'mse',\n",
    "            'max_depth':12,\n",
    "            'max_features':'auto',\n",
    "            'min_samples_split':2,\n",
    "            'min_samples_leaf':1,\n",
    "            'random_state':736283}\n",
    "\n",
    "adaParams = {'n_estimators':500, 'random_state':736283, 'learning_rate':1}\n",
    "\n",
    "gbrParams = {'n_estimators':800, \n",
    "             'random_state':736283,\n",
    "             'max_depth':8,\n",
    "             'criterion':'friedman_mse',\n",
    "             'max_features':'auto',\n",
    "             'min_samples_split':3\n",
    "             }\n",
    "\n",
    "lgbmParams = {'boosting_type':'gbdt',\n",
    "               'random_state':736283,\n",
    "               'num_leaves':400,\n",
    "               'min_data_in_leaf':5,\n",
    "               'max_bin':500,\n",
    "               'learning_rate':0.08,\n",
    "               'n_estimators':300,\n",
    "               'n_jobs':-1,\n",
    "               'subsample':0.8\n",
    "        }\n",
    "\n",
    "forestParams = {'bootstrap': True,\n",
    "             'max_depth': 70,\n",
    "             'max_features': 'auto',\n",
    "             'min_samples_leaf': 4,\n",
    "             'min_samples_split': 10,\n",
    "             'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_StackingModel_complex():\n",
    "    adaModel = AdaBoostRegressor(DecisionTreeRegressor(**adaDTR_dtrParams), **adaDTR_adaParams8)\n",
    "    etrModel = ExtraTreesRegressor(**etrParams)\n",
    "    xgbModel = XGBRegressor(**xgbParams)\n",
    "    rfgModel = RandomForestRegressor(**rfgParams)\n",
    "    gbrModel = GradientBoostingRegressor(**gbrParams)\n",
    "    adaETRModel = AdaBoostRegressor(ExtraTreeRegressor(**etParams),**adaParams)\n",
    "    lgbmModel = LGBMRegressor(**lgbmParams)\n",
    "    \n",
    "    forest = RandomForestRegressor(**forestParams)\n",
    "    \n",
    "    stregr = StackingRegressor(regressors=[adaModel, etrModel, gbrModel, adaETRModel, lgbmModel, xgbModel], meta_regressor=forest)\n",
    "    \n",
    "    return stregr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_StackingModel():\n",
    "    adaModel = AdaBoostRegressor(DecisionTreeRegressor(),n_estimators=100)\n",
    "    etrModel = ExtraTreesRegressor(n_estimators=100)\n",
    "    gbrModel = GradientBoostingRegressor(n_estimators=100)\n",
    "    adaETRModel = AdaBoostRegressor(ExtraTreeRegressor(),n_estimators=100)\n",
    "    lgb = LGBMRegressor(learning_rate=0.8,n_estimators=100) #8000\n",
    "    xgb =XGBRegressor(n_estimators=18000) #18000 rmse 88\n",
    "#     xgb = XGBRegressor(max_depth=10, n_estimators=18000, learning_rate=0.1) #best score\n",
    "#     xgb = XGBRegressor(max_depth=5, min_child_weight=5, n_estimators=18000, learning_rate=0.1, subsample=0.8)\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    ridge = Ridge(random_state=1)\n",
    "    lasso = Lasso(random_state=1)\n",
    "    svr_rbf = SVR(kernel='rbf')\n",
    "    forest = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "#     forest = RandomForestRegressor(**forestParams)\n",
    "    neural = MLPRegressor(hidden_layer_sizes=(100,10000,100),max_iter=500)\n",
    "    \n",
    "    # current best score\n",
    "    stregr = StackingRegressor(regressors=[adaModel, etrModel, gbrModel, adaETRModel, lgb, xgb], meta_regressor=forest)\n",
    "    \n",
    "    return stregr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def xgb_GridSearchCV():\n",
    "    cv_params = {'learning_rate': [0.1, 0.01], 'subsample': [0.7,0.8,0.9]}\n",
    "    xgb = XGBRegressor(max_depth=5, min_child_weight=5, n_estimators=1000, learning_rate=0.1, subsample=0.8)\n",
    "    optimized_GBM = GridSearchCV(xgb, \n",
    "                            cv_params,\n",
    "                                scoring='r2', cv = 5, n_jobs = -1) \n",
    "    return optimized_GBM\n",
    "\n",
    "#'max_depth': 5, 'min_child_weight': 5\n",
    "#learning_rate': 0.1, 'subsample': 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_optimize():\n",
    "    train_xgdmat = xgb.DMatrix(train_features, train_labels.iloc[:, 0])\n",
    "    test_xgdmat = xgb.DMatrix(test_features, test_labels.iloc[:, 0])\n",
    "    params = {'max_depth':5, \n",
    "              'min_child_weight':5, \n",
    "              'n_estimators':1000, \n",
    "              'learning_rate':0.1,\n",
    "              'subsample':0.8,\n",
    "              'objective':'reg:linear'}\n",
    "    \n",
    "#     model = xgb.train(params, \n",
    "#                     train_xgdmat, \n",
    "#                     num_boost_round = 3000, \n",
    "#                     evals=[(test_xgdmat, \"Test\")],\n",
    "#                     early_stopping_rounds = 100)\n",
    "    \n",
    "    model = xgb.train(params, \n",
    "                    train_xgdmat, \n",
    "                    num_boost_round = 2370)\n",
    "    return model\n",
    "    \n",
    "#2370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_StackingModel()\n",
    "# model = xgb_with_optimization()\n",
    "# model = xgb_optimize()\n",
    "# test_xgdmat = xgb.DMatrix(test_features)\n",
    "# pred = model.predict(test_xgdmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_features, train_labels.iloc[:, 0])\n",
    "pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 28.5751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_labels.iloc[:, 0], pred)\n",
    "\n",
    "print(\"RMSE: %.4f\\n\" % sqrt(mse))\n",
    "# 28.40\n",
    "# standard 28.3863\n",
    "# minmax 28.4783\n",
    "# maxabs 28.2943 with neural 28.4779\n",
    "# normal 30.1721\n",
    "# print(model.grid_scores_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importances = model.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(train_features.shape[1]), importances[indices],\n",
    "#        color=\"r\", align=\"center\")\n",
    "# plt.xticks(range(train_features.shape[1]), indices)\n",
    "# plt.xlim([-1, train_features.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = pd.read_csv('test_values.csv')\n",
    "\n",
    "test_row_id = testX.row_id\n",
    "testX.drop('row_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX.area__rucc = testX.area__rucc.astype(\"category\").cat.codes\n",
    "testX.area__urban_influence = testX.area__urban_influence.astype(\"category\").cat.codes\n",
    "testX.econ__economic_typology = testX.econ__economic_typology.astype(\"category\").cat.codes\n",
    "testX.yr = testX.yr.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testX = testX.join(pd.get_dummies(data=testX.area__rucc))\n",
    "# testX = testX.join(pd.get_dummies(data=testX.area__urban_influence))\n",
    "# testX = testX.join(pd.get_dummies(data=testX.econ__economic_typology))\n",
    "# testX.yr = testX.yr.astype(\"category\").cat.codes\n",
    "# testX.drop(['area__rucc', 'area__urban_influence', 'econ__economic_typology'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in testX.columns:\n",
    "    #trainX[col].fillna(trainX[col].mean(), inplace=True)\n",
    "    testX[col].fillna(testX[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in testX.columns:\n",
    "#     #trainX[col].fillna(trainX[col].mean(), inplace=True)\n",
    "#     testX[col].fillna(testX[0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area__rucc</th>\n",
       "      <th>area__urban_influence</th>\n",
       "      <th>econ__economic_typology</th>\n",
       "      <th>econ__pct_civilian_labor</th>\n",
       "      <th>econ__pct_unemployment</th>\n",
       "      <th>econ__pct_uninsured_adults</th>\n",
       "      <th>econ__pct_uninsured_children</th>\n",
       "      <th>demo__pct_female</th>\n",
       "      <th>demo__pct_below_18_years_of_age</th>\n",
       "      <th>demo__pct_aged_65_years_and_older</th>\n",
       "      <th>...</th>\n",
       "      <th>health__pct_diabetes</th>\n",
       "      <th>health__pct_low_birthweight</th>\n",
       "      <th>health__pct_excessive_drinking</th>\n",
       "      <th>health__pct_physical_inacticity</th>\n",
       "      <th>health__air_pollution_particulate_matter</th>\n",
       "      <th>health__homicides_per_100k</th>\n",
       "      <th>health__motor_vehicle_crash_deaths_per_100k</th>\n",
       "      <th>health__pop_per_dentist</th>\n",
       "      <th>health__pop_per_primary_care_physician</th>\n",
       "      <th>yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [area__rucc, area__urban_influence, econ__economic_typology, econ__pct_civilian_labor, econ__pct_unemployment, econ__pct_uninsured_adults, econ__pct_uninsured_children, demo__pct_female, demo__pct_below_18_years_of_age, demo__pct_aged_65_years_and_older, demo__pct_hispanic, demo__pct_non_hispanic_african_american, demo__pct_non_hispanic_white, demo__pct_american_indian_or_alaskan_native, demo__pct_asian, demo__pct_adults_less_than_a_high_school_diploma, demo__pct_adults_with_high_school_diploma, demo__pct_adults_with_some_college, demo__pct_adults_bachelors_or_higher, demo__birth_rate_per_1k, demo__death_rate_per_1k, health__pct_adult_obesity, health__pct_adult_smoking, health__pct_diabetes, health__pct_low_birthweight, health__pct_excessive_drinking, health__pct_physical_inacticity, health__air_pollution_particulate_matter, health__homicides_per_100k, health__motor_vehicle_crash_deaths_per_100k, health__pop_per_dentist, health__pop_per_primary_care_physician, yr]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[pd.isnull(testX).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# scaler = preprocessing.MaxAbsScaler()\n",
    "# scaler = preprocessing.Normalizer()\n",
    "\n",
    "# scaler.fit(trainX)\n",
    "# trainX = scaler.transform(trainX)\n",
    "# testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testX.drop(['yr',\n",
    "#  'health__air_pollution_particulate_matter',\n",
    "#  'health__homicides_per_100k',\n",
    "#  'demo__birth_rate_per_1k',\n",
    "#  'demo__death_rate_per_1k'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_StackingModel()\n",
    "model.fit(trainX, trainY.iloc[:, 0])\n",
    "pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 33)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_row_id = pd.DataFrame({'row_id': test_row_id})\n",
    "predictions = pd.DataFrame({'heart_disease_mortality_per_100k': pred})\n",
    "final_prediction = test_row_id.join(predictions)\n",
    "final_prediction.heart_disease_mortality_per_100k = predictions.heart_disease_mortality_per_100k.astype(int)\n",
    "final_prediction.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
